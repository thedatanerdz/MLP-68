{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"from fastapi import FastAPI, File, UploadFile\nfrom fastapi.middleware.cors import CORSMiddleware\nimport uvicorn\nimport numpy as np\nfrom io import BytesIO\nfrom PIL import Image\nimport tensorflow as tf","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"1. Importing FastAPI, File, UploadFile:\n- *from fastapi import FastAPI, File, UploadFile*: This line imports the necessary components from the FastAPI framework. FastAPI is a modern web framework for building APIs with Python.\n\n2. Importing CORSMiddleware:\n- *from fastapi.middleware.cors import CORSMiddleware*: This line imports the CORS (Cross-Origin Resource Sharing) middleware from FastAPI. CORS is used to enable cross-origin requests, allowing your API to be accessed by web applications running on different domains.\n\n3. Importing uvicorn:\n- import uvicorn: Uvicorn is an ASGI (Asynchronous Server Gateway Interface) server, commonly used for running FastAPI applications. It's used later in the code to start the server.\n\n4. Importing numpy and other libraries:\n- import numpy as np: NumPy is a popular library for numerical operations in Python. It's often used in machine learning for data manipulation.\n- from io import BytesIO: BytesIO is an in-memory binary stream used for handling binary data.\n- from PIL import Image: PIL (Python Imaging Library) is used for image processing. It's commonly used for opening, manipulating, and saving image files.\n- import tensorflow as tf: TensorFlow is a popular machine learning library. In this context, it is likely used for loading a pre-trained machine learning model for inference.\n\nNow, let's briefly explain the purpose of the code:\n\n* FastAPI is used to create a web application.\n* CORSMiddleware is used to enable Cross-Origin Resource Sharing, allowing your API to be accessed from different domains.\n* uvicorn is a server that can run the FastAPI application.\n* numpy is often used for data manipulation, possibly for processing data in the context of the machine learning model.\n* BytesIO is used for handling binary data, which may be relevant for processing image data.\n* PIL is used for image manipulation, and Image is a class for working with images.\n* tensorflow is used for machine learning tasks and may be used for loading and running a pre-trained model.\n* The code you provided is just the import section of a FastAPI application. To understand the full functionality of the API and how these packages are used, you would need to see the rest of the code, which would include the actual API endpoints and model serving logic.","metadata":{}},{"cell_type":"code","source":"app = FastAPI()","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"The line app = FastAPI() creates a FastAPI application instance named app. This instance will be used to define and configure your API's endpoints, middleware, request handlers, and other settings.\n\nWith this instance, you can start building your API by adding routes, request handlers, and other components. For example, you can define routes that handle incoming HTTP requests, specify data models for request and response objects, add middleware for authentication or CORS handling, and more.","metadata":{}},{"cell_type":"code","source":"origins = [\n    \"http://localhost\",\n    \"http://localhost:3000\",\n]","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"The origins list is a configuration setting used with the CORSMiddleware in a FastAPI application. This setting defines a list of allowed origins (i.e., domains or URLs) that are permitted to make cross-origin requests to your API. Cross-origin requests occur when a web application running on one domain tries to access resources on a different domain through AJAX or other HTTP methods.\n\nIn this specific case, the origins list allows requests from the following two origins:\n\n\"http://localhost\": This allows requests from a web application running on the local machine at the default HTTP port (port 80). Web applications running on \"http://localhost\" are often used for development and testing purposes.\n\n\"http://localhost:3000\": This allows requests from a web application running on the local machine at port 3000. This is another common setup for development and testing, especially if you are using tools like React or other front-end frameworks that use this port by default.\n\nBy specifying these origins in the origins list, you are configuring your FastAPI application to accept requests from these specific domains. Any requests coming from other origins will be denied by default, helping to prevent potential security vulnerabilities related to cross-origin requests.\n\nYou would typically use this configuration when setting up the CORSMiddleware in your FastAPI application to control which domains are allowed to access your API.","metadata":{}},{"cell_type":"code","source":"app.add_middleware(\n    CORSMiddleware,\n    allow_origins=origins,\n    allow_credentials=True,\n    allow_methods=[\"*\"],\n    allow_headers=[\"*\"],\n)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"The code you provided adds the CORSMiddleware to your FastAPI application (app) with specific configuration options. Let's break down what each of these options does:\n\nallow_origins=origins: This option specifies the list of allowed origins (domains or URLs) that are permitted to make cross-origin requests to your API. In your case, it allows requests from the origins specified in the origins list, which are \"http://localhost\" and \"http://localhost:3000\".\n\nallow_credentials=True: This option allows the inclusion of credentials (e.g., cookies, HTTP authentication) when making cross-origin requests. If set to True, it indicates that the client-side JavaScript code running in the browser can include credentials when making requests to your API.\n\nallow_methods=[\"*\"]: This option specifies which HTTP methods are allowed for cross-origin requests. The value [\"*\"] means that all HTTP methods are allowed, which includes common methods like GET, POST, PUT, DELETE, etc. You can restrict this to specific methods if needed.\n\nallow_headers=[\"*\"]: This option specifies which HTTP headers are allowed for cross-origin requests. Similar to allow_methods, [\"*\"] means that all headers are allowed. You can restrict this to specific headers if needed. Allowing all headers might be acceptable for development or internal use, but for production APIs, it's a good practice to be more specific about which headers are allowed.\n\nBy adding the CORSMiddleware with these options to your FastAPI application, you are configuring it to handle cross-origin requests from the specified origins, allow credentials to be included in requests, and permit all HTTP methods and headers. This configuration is commonly used when you want to make your API accessible to web applications running on different domains while ensuring security and control over the allowed origins and request handling.","metadata":{}},{"cell_type":"code","source":"MODEL = tf.keras.models.load_model(\"../saved_models/1\")","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"The line MODEL = tf.keras.models.load_model(\"../saved_models/1\") is loading a pre-trained machine learning model using TensorFlow's Keras API.","metadata":{}},{"cell_type":"code","source":"CLASS_NAMES = [\"Early Blight\", \"Late Blight\", \"Healthy\"]","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"The CLASS_NAMES list contains class labels or names that correspond to the output classes of a machine learning model. In the context of machine learning, particularly in image classification tasks, class labels are used to represent the different categories or classes that the model can predict when given an input.\n\nIn your specific case, it seems that you're working with a model that is designed to classify images into one of three classes: \"Early Blight,\" \"Late Blight,\" or \"Healthy.\" These class names likely represent different health conditions or states for something, such as plants or objects in the images.\n\nHaving a CLASS_NAMES list like this can be helpful for several purposes:\n\nInterpretation of Model Predictions: When the model makes predictions, the class name associated with the predicted class index can be easily retrieved using this list. For example, if the model predicts class 1, you can use CLASS_NAMES[1] to get the corresponding class name, which might be \"Late Blight.\"\n\nResponse Formatting: When your FastAPI API serves predictions, you can include the class names in the API response to provide a more human-readable interpretation of the model's output.","metadata":{}},{"cell_type":"code","source":"@app.get(\"/ping\")\nasync def ping():\n    return \"Hello, I am alive\"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"The @app.get(\"/ping\") decorator defines a route in your FastAPI application that responds to HTTP GET requests made to the \"/ping\" endpoint. When a client sends a GET request to this endpoint, the ping function is executed, and it returns a simple string response, \"Hello, I am alive.\"\n\nThe purpose of this route is typically to serve as a simple health check endpoint. When you access the \"/ping\" endpoint, it can be used to confirm that the API server is up and running. This is especially useful for monitoring and debugging purposes in a production environment.","metadata":{}},{"cell_type":"code","source":"def read_file_as_image(data) -> np.ndarray:\n    image = np.array(Image.open(BytesIO(data)))\n    return image","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"The read_file_as_image function is a utility function for reading binary image data and converting it into a NumPy array representing the image. Here's a breakdown of what this function does:\n\ndef read_file_as_image(data) -> np.ndarray:: This line defines a function named read_file_as_image that takes one argument, data, which is expected to be binary image data. The function is annotated to return a NumPy array (np.ndarray) representing the image.\n\nimage = np.array(Image.open(BytesIO(data))): This line performs the following steps:\n\nBytesIO(data): It creates an in-memory binary stream (BytesIO object) from the data provided as an argument. This allows reading binary data as if it were a file.\nImage.open(...): It opens the binary data as an image using the PIL (Python Imaging Library) Image.open method.\nnp.array(...): It converts the opened image into a NumPy array. Each pixel of the image is represented as a value in the NumPy array, making it suitable for further processing or analysis.\nreturn image: Finally, the function returns the NumPy array representing the image.\n\nThis function can be useful in the context of processing image data received as part of an HTTP request, for example, when a client uploads an image to your API. You can call this function to convert the binary image data into a format that can be used for further processing, such as feeding it into a machine learning model for prediction or performing image analysis tasks.","metadata":{}},{"cell_type":"code","source":"@app.post(\"/predict\")\nasync def predict(\n    file: UploadFile = File(...)\n):\n    image = read_file_as_image(await file.read())\n    img_batch = np.expand_dims(image, 0)\n    \n    predictions = MODEL.predict(img_batch)\n\n    predicted_class = CLASS_NAMES[np.argmax(predictions[0])]\n    confidence = np.max(predictions[0])\n    return {\n        'class': predicted_class,\n        'confidence': float(confidence)\n    }","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"The @app.post(\"/predict\") decorator defines a route in your FastAPI application that responds to HTTP POST requests made to the \"/predict\" endpoint. This route is typically used for making predictions based on image data uploaded by the client. Here's a breakdown of what this route does:\n\nasync def predict(file: UploadFile = File(...)):: This line defines an asynchronous function named predict that takes one parameter, file, which is expected to be an uploaded file containing image data. The UploadFile type indicates that it's a file upload field. The = File(...) syntax means that this parameter is required.\n\nimage = read_file_as_image(await file.read()): Inside the predict function, it reads the uploaded image file using await file.read(), which is an asynchronous operation. Then, it calls the read_file_as_image function (defined earlier) to convert the binary image data into a NumPy array representing the image.\n\nimg_batch = np.expand_dims(image, 0): It prepares the image for prediction by creating a batch with a single image. In many machine learning models, including deep learning models, input data is often organized into batches. Here, np.expand_dims is used to add an extra dimension to the array to create a batch containing a single image.\n\npredictions = MODEL.predict(img_batch): It uses the pre-trained machine learning model (MODEL) to make predictions on the image batch. This is where the machine learning model processes the image and returns predicted class probabilities.\n\npredicted_class = CLASS_NAMES[np.argmax(predictions[0])]: It finds the index of the class with the highest predicted probability using np.argmax, and then uses CLASS_NAMES to map that index to the corresponding class name. This determines the predicted class.\n\nconfidence = np.max(predictions[0]): It calculates the maximum predicted probability, which can be considered as a confidence score for the predicted class.\n\nThe function returns a dictionary with two keys:\n\n'class': The predicted class name.\n'confidence': The confidence score for the prediction.\nThe purpose of this route is to accept an uploaded image, use the pre-trained machine learning model to predict the class of the image, and return the predicted class along with a confidence score to the client. This is a common pattern for building image classification APIs.\n\n\n\n\n\n\n\n","metadata":{}},{"cell_type":"code","source":"if __name__ == \"__main__\":\n    uvicorn.run(app, host='localhost', port=8000)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"The if __name__ == \"__main__\": block is a common pattern used in Python scripts to ensure that a certain block of code is only executed when the script is run directly (as the main program), not when it is imported as a module into another script. Here's what the code you provided does:\n\nif __name__ == \"__main__\":: This line checks if the special Python variable __name__ is set to \"__main__\". When a Python script is run directly, __name__ is set to \"__main__\". If the script is imported as a module into another script, __name__ is set to the name of the module.\n\nuvicorn.run(app, host='localhost', port=8000): If the script is being run directly (i.e., __name__ is \"__main__\"), this line starts the FastAPI application using the Uvicorn ASGI server. It specifies the host as 'localhost' and the port as 8000. This means that the FastAPI application will be accessible at 'http://localhost:8000/' when the script is run.\n\nIn summary, this block of code ensures that your FastAPI application is started using Uvicorn when the script is run as the main program, allowing you to launch and test your API locally by running this script. It will not run this code if the script is imported as a module into another Python script, ensuring that the FastAPI application is only started when intended.","metadata":{}}]}